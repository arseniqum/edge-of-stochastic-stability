{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template Notebook for Edge of Stochastic Stability Experiments\n",
    "\n",
    "This notebook serves as a template for running measurements on neural networks (both trained and untrained) in the context of Edge of Stochastic Stability research. \n",
    "\n",
    "## Purpose\n",
    "- Creates and initalizes neural networks (with the given initialization seed for reproducability)\n",
    "- Loads corresponding datasets (with the given dataset seed for irreducability)\n",
    "- Loads pre-trained network checkpoints\n",
    "- Evaluates training loss and other metrics\n",
    "- Provides a foundation for EOSS-related measurements and analysis\n",
    "\n",
    "Use this as a starting point for your own experiments and measurements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "import torch as T\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange, repeat\n",
    "from torch import linalg as LA\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.autograd import grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "from utils.data import prepare_dataset, get_dataset_presets\n",
    "from utils.nets import SquaredLoss, prepare_net_dataset_specific, MLP, CNN, prepare_net, initialize_net, prepare_optimizer, get_model_presets, get_path_of_last_net\n",
    "from utils.measure import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER = Path('/scratch/gpfs/andreyev/datasets/') \n",
    "RESULTS_FOLDER = Path('/scratch/gpfs/andreyev/eoss/results')\n",
    "device = (T.device('cuda') if T.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cifar10'\n",
    "model_type = 'mlp'\n",
    "num_data = 8192\n",
    "no_init = True\n",
    "init_scale = 0.3\n",
    "classes = None\n",
    "dataset_seed = 345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_presets = get_dataset_presets()\n",
    "\n",
    "data = prepare_dataset(dataset, DATASET_FOLDER, num_data, classes, dataset_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train.float().to(device)\n",
    "Y = Y_train.float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = prepare_net_dataset_specific(model_type, dataset)\n",
    "\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = SquaredLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Initialize or load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not no_init:\n",
    "    initialize_net(net, init_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It should be epoch 126 around step 65000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "step_to_load_around = 65_000\n",
    "\n",
    "steps_in_epoch = len(X_train) // batch_size\n",
    "\n",
    "epoch_to_load = step_to_load_around // steps_in_epoch\n",
    "print(f'It should be epoch {epoch_to_load} around step {step_to_load_around}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_path = \"cifar10_mlp/20250328_0221_53_lr0.01000_b16\"\n",
    "\n",
    "checkpoint_path = RESULTS_FOLDER / run_path / 'checkpoints'\n",
    "\n",
    "net_to_load = get_path_of_last_net(checkpoint_path)\n",
    "# net_to_load = checkpoint_path / f'net_{epoch_to_load}.pt'\n",
    "\n",
    "net.load_state_dict(torch.load(net_to_load, weights_only=True, map_location=device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00012003588199149817"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = net(X_train[:4])\n",
    "loss = loss_fn(preds, Y_train[:4])\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8840587139129639"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = net(X_test[:4])\n",
    "loss = loss_fn(preds, Y_test[:4])\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are calculating the total loss to check that the dataset was loaded correctly -- as otherwise the training loss would be higher "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00030041515128687024"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = net(X_train)\n",
    "loss = loss_fn(preds, Y_train)\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 1.0000 (100.00%)\n",
      "Test accuracy: 0.44220 (44.22%)\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(predictions, targets):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy given the model predictions and target labels.\n",
    "    \n",
    "    Args:\n",
    "        predictions: tensor of shape (num_samples, num_classes) with model predictions\n",
    "        targets: tensor of shape (num_samples, num_classes) with one-hot encoded labels\n",
    "                or tensor of shape (num_samples,) with class indices\n",
    "    \n",
    "    Returns:\n",
    "        accuracy: float representing the accuracy (0.0 to 1.0)\n",
    "    \"\"\"\n",
    "    # Get the predicted class (highest value in each row)\n",
    "    pred_classes = torch.argmax(predictions, dim=1)\n",
    "    \n",
    "    # Check if targets are one-hot encoded or class indices\n",
    "    if len(targets.shape) > 1 and targets.shape[1] > 1:\n",
    "        # One-hot encoded targets\n",
    "        true_classes = torch.argmax(targets, dim=1)\n",
    "    else:\n",
    "        # Class indices (1D tensor)\n",
    "        true_classes = targets\n",
    "    \n",
    "    # Compare and compute accuracy\n",
    "    correct = (pred_classes == true_classes).sum().item()\n",
    "    total = targets.size(0)\n",
    "    \n",
    "    return correct / total\n",
    "\n",
    "# Calculate accuracy on training data\n",
    "train_preds = net(X_train)\n",
    "train_accuracy = calculate_accuracy(train_preds, Y_train)\n",
    "print(f\"Training accuracy: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Calculate accuracy on test data\n",
    "test_preds = net(X_test)\n",
    "test_accuracy = calculate_accuracy(test_preds, Y_test)\n",
    "print(f\"Test accuracy: {test_accuracy:.5f} ({test_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
